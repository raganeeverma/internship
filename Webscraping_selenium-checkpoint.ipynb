{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a010df9",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12db8850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.5.0-py3-none-any.whl (995 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.0.0rc9-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.0.0rc9 h11-0.14.0 outcome-1.2.0 selenium-4.5.0 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca7b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver # ready to start the browser\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from selenium.webdriver.common.by  import By\n",
    "\n",
    "import time\n",
    "\n",
    "#from selenium.common.exceptions import StateElementReferenceException,NoSuchElementException\n",
    "\n",
    "#from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81a15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wedriver downloading done by using link http:// chromedriver.chromium.org/downlods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302aefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "186a74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to  the url that i want to open \n",
    "driver.get(\"https://www.naukri.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce092c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#job-title, job-location, company_name, experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256675e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enterung designation and location as required in question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Analyst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6790a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input \")# absolute x_path\n",
    "location.send_keys(\"Bangalore\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e3f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")# absolute x_path\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f57a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list whatevwe we want to scrap\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "job_location=[]\n",
    "experience_required=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db89fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')# relative x_path\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "    \n",
    "# sraping company name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# sraping company location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#_ sraping experience_required from given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5aa5829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(experience_required),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2871978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe from above data\n",
    "\n",
    "df=pd.DataFrame({\"job_title\":job_title,\"company_name\":company_name,\"job_location\":job_location,\"experience_required\":experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14aa2934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Goalreify Ventures</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Goalreify Ventures</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title        company_name  \\\n",
       "0                                Senior Data Analyst          Latentview   \n",
       "1                        Data Analyst - CRM Platform   Artech infosystem   \n",
       "2  Hiring For Data Analyst (DA)/ Team Lead (TL) -...           Cognizant   \n",
       "3                Payroll Transformation Data Analyst   Arrow Electronics   \n",
       "4            Master Data Management Business Analyst           Accenture   \n",
       "5  Data Analytics and Interpretation Business Ana...           Accenture   \n",
       "6                                       Data Analyst                 ANZ   \n",
       "7                                       Data Analyst                 ANZ   \n",
       "8                                Senior Data Analyst  Goalreify Ventures   \n",
       "9                                Senior Data Analyst  Goalreify Ventures   \n",
       "\n",
       "                                        job_location experience_required  \n",
       "0                       Bangalore/Bengaluru, Chennai             3-6 Yrs  \n",
       "1  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             1-6 Yrs  \n",
       "2  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...             3-8 Yrs  \n",
       "3                                Bangalore/Bengaluru            5-10 Yrs  \n",
       "4                                Bangalore/Bengaluru             6-8 Yrs  \n",
       "5                                Bangalore/Bengaluru             6-8 Yrs  \n",
       "6                                Bangalore/Bengaluru            7-12 Yrs  \n",
       "7                                Bangalore/Bengaluru            7-12 Yrs  \n",
       "8                                Bangalore/Bengaluru             3-6 Yrs  \n",
       "9                                Bangalore/Bengaluru             4-6 Yrs  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01147877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c7c8745",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0720288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver # ready to start the browser\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from selenium.webdriver.common.by  import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e34878ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# connect to  the url that i want to open \n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60143d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enterung designation and location as required in question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a10b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input \")# absolute x_path\n",
    "location.send_keys(\"Bangalore\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035215f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")# absolute x_path\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7da8f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list whatevwe we want to scrap\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "job_location=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3da8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')# relative x_path\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "    \n",
    "# sraping company name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# sraping company location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14a86a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ce4c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe from above data\n",
    "\n",
    "ds=pd.DataFrame({\"job_title\":job_title,\"company_name\":company_name,\"job_location\":job_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d2d766d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Goalreify Ventures</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Goalreify Ventures</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title        company_name  \\\n",
       "0                                Senior Data Analyst          Latentview   \n",
       "1                        Data Analyst - CRM Platform   Artech infosystem   \n",
       "2  Hiring For Data Analyst (DA)/ Team Lead (TL) -...           Cognizant   \n",
       "3                Payroll Transformation Data Analyst   Arrow Electronics   \n",
       "4            Master Data Management Business Analyst           Accenture   \n",
       "5  Data Analytics and Interpretation Business Ana...           Accenture   \n",
       "6                                       Data Analyst                 ANZ   \n",
       "7                                       Data Analyst                 ANZ   \n",
       "8                                Senior Data Analyst  Goalreify Ventures   \n",
       "9                                Senior Data Analyst  Goalreify Ventures   \n",
       "\n",
       "                                        job_location  \n",
       "0                       Bangalore/Bengaluru, Chennai  \n",
       "1  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...  \n",
       "2  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea7e30",
   "metadata": {},
   "source": [
    "q 3 In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7713b7e",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702a6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver # ready to start the browser\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from selenium.webdriver.common.by  import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9af4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# connect to  the url that i want to open \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c299e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input \")# absolute x_path\n",
    "Product.send_keys(\"sunglasses\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c93924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')# absolute x_path\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a016a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list whatevwe we want to scrap\n",
    "Product_Brand=[]\n",
    "Product_Description=[]\n",
    "Product_Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d217ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    # sraping v from given page\n",
    "    Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')# relative x_path\n",
    "    for i in Brand_tags[0:100]:\n",
    "        Brand=i.text\n",
    "        Product_Brand.append(Brand)\n",
    "\n",
    "    \n",
    "    # sraping Product_Description from given page\n",
    "    Description_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in Description_tags[0:100]:\n",
    "        Description=i.text\n",
    "        Product_Description.append(Description)\n",
    "    \n",
    "    # sraping Product_Price from given page\n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in Price_tags[0:100]:\n",
    "        Price=i.text\n",
    "        Product_Price.append(Price)\n",
    "        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')# relative x_path\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32366f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dfc917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_glass=pd.DataFrame({\"Product_Brand\":Product_Brand,\"Product_Description\":Product_Description,\"Product_Price\":Product_Price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37f9007c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Product_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOSSIL</td>\n",
       "      <td>Others Oval Sunglasses (56)</td>\n",
       "      <td>₹2,069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARRERA</td>\n",
       "      <td>Others Rectangular Sunglasses (52)</td>\n",
       "      <td>₹2,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Wayfarer, Retro Squar...</td>\n",
       "      <td>₹424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Aviator Sunglasses (88)</td>\n",
       "      <td>₹192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Product_Brand                                Product_Description  \\\n",
       "0               FOSSIL                        Others Oval Sunglasses (56)   \n",
       "1              CARRERA                 Others Rectangular Sunglasses (52)   \n",
       "2             Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3             Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "4    SHAAH COLLECTIONS                UV Protection Round Sunglasses (54)   \n",
       "..                 ...                                                ...   \n",
       "115       Singco India  Gradient, Toughened Glass Lens, UV Protection ...   \n",
       "116           Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "117          ROYAL SON  Polarized, UV Protection Wayfarer, Retro Squar...   \n",
       "118           Fastrack       UV Protection Aviator Sunglasses (Free Size)   \n",
       "119       Silver Kartz              UV Protection Aviator Sunglasses (88)   \n",
       "\n",
       "    Product_Price  \n",
       "0          ₹2,069  \n",
       "1          ₹2,999  \n",
       "2            ₹499  \n",
       "3            ₹449  \n",
       "4             ₹79  \n",
       "..            ...  \n",
       "115          ₹507  \n",
       "116          ₹459  \n",
       "117          ₹424  \n",
       "118          ₹459  \n",
       "119          ₹192  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_glass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727a111",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "    \n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6207300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver # ready to start the browser\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from selenium.webdriver.common.by  import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96934cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# connect to  the url that i want to open \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2350306",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input \")# absolute x_path\n",
    "Product.send_keys(\"iphone11\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53fadf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')# absolute x_path\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e870fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_link=driver.find_elements(By.XPATH,'//a[@class=\"_1fQZEK\"]')# absolute x_path\n",
    "#product_link[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac23d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in product_link :\n",
    "    i.get_attribute(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f5b1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list whatevwe we want to scrap\n",
    "iphone11_Rating=[]\n",
    "iphone11_Review_summary=[]\n",
    "iphone11_Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b436e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "\n",
    "    Rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')# relative x_path\n",
    "    for i in Rating_tags:\n",
    "        iphone11_Rating.append(i.text)\n",
    "\n",
    "    Full_review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in Full_review_tags[0:100]:\n",
    "        iphone11_Full_review.append(i.text)\n",
    "    \n",
    "    Review_summary_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in Review_summary_tags:\n",
    "        iphone11_Review_summary.append(i.text)\n",
    "        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')# relative x_path\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "567d2420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len( iphone11_Rating),len(iphone11_Full_review),len(iphone11_Review_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eab0992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Full_review</th>\n",
       "      <th>Review_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Good phone but not for the power user</td>\n",
       "      <td>Apple's iPhone series have been known for thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This review is after 6 year of purchasing this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice product..just love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Fast performance to previous iPhone x\\nGood ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Fantastic and prompt delivery.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                            Full_review  \\\n",
       "0       5                       Perfect product!   \n",
       "1       5                               Terrific   \n",
       "2       3  Good phone but not for the power user   \n",
       "3       5                                 Super!   \n",
       "4       4                        Value-for-money   \n",
       "..    ...                                    ...   \n",
       "95      5                              Wonderful   \n",
       "96      4                   Good quality product   \n",
       "97      5                       Perfect product!   \n",
       "98      5                              Fabulous!   \n",
       "99      5                  Mind-blowing purchase   \n",
       "\n",
       "                                       Review_summary  \n",
       "0   After using 3 years mobile review. Excellent &...  \n",
       "1   I am using the phone for last 5 years and foun...  \n",
       "2   Apple's iPhone series have been known for thei...  \n",
       "3   This review is after 6 year of purchasing this...  \n",
       "4   I'm Really happy with the product\\nDelivery wa...  \n",
       "..                                                ...  \n",
       "95                         Nice product..just love it  \n",
       "96  impressively Nice......\\nOne of the greatest i...  \n",
       "97                         Nice products thanks flkat  \n",
       "98  Fast performance to previous iPhone x\\nGood ca...  \n",
       "99                     Fantastic and prompt delivery.  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone11=pd.DataFrame({\"Rating\":iphone11_Rating,\"Full_review\":iphone11_Full_review,\"Review_summary\":iphone11_Review_summary})\n",
    "iphone11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c4b0be",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "Brand\n",
    "Product Description\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f973da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver # ready to start the browser\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from selenium.webdriver.common.by  import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13806883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "# connect to  the url that i want to open \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5e9a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input \")# absolute x_path\n",
    "Product.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58742393",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')# absolute x_path\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e19e6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list whatevwe we want to scrap\n",
    "Product_Brand=[]\n",
    "Product_Description=[]\n",
    "Product_Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f306f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    # sraping v from given page\n",
    "    Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')# relative x_path\n",
    "    for i in Brand_tags[0:100]:\n",
    "        Brand=i.text\n",
    "        Product_Brand.append(Brand)\n",
    "\n",
    "    \n",
    "    # sraping Product_Description from given page\n",
    "    Description_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in Description_tags[0:100]:\n",
    "        Description=i.text\n",
    "        Product_Description.append(Description)\n",
    "    \n",
    "    # sraping Product_Price from given page\n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in Price_tags[0:100]:\n",
    "        Price=i.text\n",
    "        Product_Price.append(Price)\n",
    "        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')# relative x_path\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f62469bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Product_Brand),len(Product_Description),len(Product_Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "204d748b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Product_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wildcraft</td>\n",
       "      <td>True Black Shoe Sneakers For Men</td>\n",
       "      <td>₹1,069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR</td>\n",
       "      <td>Casual White Sneakers For Men</td>\n",
       "      <td>₹239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>JUPITER Men's Retro Color Blocked Light Weight...</td>\n",
       "      <td>₹1,320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>K- FOOTLANCE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneaker Sneakers For Men</td>\n",
       "      <td>₹206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>'Trends'</td>\n",
       "      <td>Fashionable casual sneaker shoes Sneakers For Men</td>\n",
       "      <td>₹380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Product_Brand                                Product_Description  \\\n",
       "0       Wildcraft                   True Black Shoe Sneakers For Men   \n",
       "1              TR                      Casual White Sneakers For Men   \n",
       "2        RED TAPE                                   Sneakers For Men   \n",
       "3          BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "4          BRUTON  Lightweight Pack Of 1 Trendy Sneakers Sneakers...   \n",
       "..            ...                                                ...   \n",
       "115   bacca bucci  JUPITER Men's Retro Color Blocked Light Weight...   \n",
       "116      ASTEROID  Original Luxury Branded Fashionable Men's Casu...   \n",
       "117  K- FOOTLANCE                                   Sneakers For Men   \n",
       "118        BRUTON                           Sneaker Sneakers For Men   \n",
       "119      'Trends'  Fashionable casual sneaker shoes Sneakers For Men   \n",
       "\n",
       "    Product_Price  \n",
       "0          ₹1,069  \n",
       "1            ₹239  \n",
       "2            ₹899  \n",
       "3            ₹191  \n",
       "4            ₹143  \n",
       "..            ...  \n",
       "115        ₹1,320  \n",
       "116          ₹399  \n",
       "117          ₹319  \n",
       "118          ₹206  \n",
       "119          ₹380  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers=pd.DataFrame({\"Product_Brand\":Product_Brand,\"Product_Description\":Product_Description,\"Product_Price\":Product_Price})\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc85999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
